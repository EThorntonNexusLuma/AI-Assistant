<!DOCTYPE html>
<html lang="en" data-embed="true">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>AI Assistant — GitHub Pages (Self-Hosted SDK)</title>

  <style>
    /* ——— your design remains intact ——— */
    * { margin: 0; padding: 0; box-sizing: border-box; }
    body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif; overflow-x: hidden; }
    .floating-icon { position: fixed; bottom: 30px; right: 30px; width: 70px; height: 70px; border-radius: 50%; background: linear-gradient(135deg, #8b5cf6, #a855f7, #c084fc); cursor: pointer; display: flex; align-items: center; justify-content: center; box-shadow: 0 8px 32px rgba(139, 92, 246, 0.3); backdrop-filter: blur(10px); border: 1px solid rgba(255, 255, 255, 0.2); z-index: 1000; animation: gentlePulse 3s ease-in-out infinite; transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1); }
    .floating-icon:hover { transform: scale(1.1); box-shadow: 0 12px 40px rgba(139, 92, 246, 0.5); }
    .floating-icon svg { width: 30px; height: 30px; color: white; }
    @keyframes gentlePulse { 0%, 100% { transform: scale(1); box-shadow: 0 8px 32px rgba(139, 92, 246, 0.3);} 50% { transform: scale(1.05); box-shadow: 0 12px 40px rgba(139, 92, 246, 0.5);} }
    .holographic-interface { position: fixed; top: 0; left: 0; width: 100vw; height: 100vh; background: linear-gradient(135deg, #f8fafc 0%, #e2e8f0 25%, #ddd6fe 50%, #c4b5fd 75%, #a78bfa 100%); backdrop-filter: blur(20px); z-index: 2000; display: flex; align-items: center; justify-content: center; opacity: 0; visibility: hidden; transition: all 0.6s cubic-bezier(0.4, 0, 0.2, 1); transform: scale(0.8) perspective(1000px) rotateX(10deg); }
    .holographic-interface.active { opacity: 1; visibility: visible; transform: scale(1) perspective(1000px) rotateX(0deg); }
    .interface-container { position: relative; max-width: 500px; width: 90%; padding: 60px 40px; text-align: center; animation: holographicFloat 4s ease-in-out infinite; }
    @keyframes holographicFloat { 0%, 100% { transform: translateY(0px) rotateX(0deg);} 50% { transform: translateY(-10px) rotateX(2deg);} }
    .voice-interface { position: relative; width: 200px; height: 200px; margin: 0 auto 40px; }
    .voice-ring { position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%); border-radius: 50%; border: 2px solid rgba(255, 255, 255, 0.3); backdrop-filter: blur(10px); }
    .ring-outer { width: 200px; height: 200px; background: radial-gradient(circle, rgba(196, 181, 253, 0.3) 0%, rgba(139, 92, 246, 0.2) 40%, transparent 70%); box-shadow: 0 0 40px rgba(139, 92, 246, 0.4), inset 0 0 20px rgba(255, 255, 255, 0.1); animation: ringPulse 3s ease-in-out infinite; }
    .ring-middle { width: 140px; height: 140px; background: radial-gradient(circle, rgba(168, 139, 250, 0.5) 0%, rgba(139, 92, 246, 0.3) 50%, transparent 70%); box-shadow: 0 0 30px rgba(168, 139, 250, 0.5), inset 0 0 15px rgba(255, 255, 255, 0.2); animation: ringPulse 3s ease-in-out infinite 0.5s; }
    .ring-inner { width: 80px; height: 80px; background: radial-gradient(circle, rgba(255, 255, 255, 0.9) 0%, rgba(196, 181, 253, 0.8) 50%, rgba(139, 92, 246, 0.6) 100%); box-shadow: 0 0 20px rgba(255, 255, 255, 0.8), 0 0 40px rgba(139, 92, 246, 0.6), inset 0 0 10px rgba(255, 255, 255, 0.3); display: flex; align-items: center; justify-content: center; animation: ringPulse 3s ease-in-out infinite 1s; }
    .mic-icon { width: 30px; height: 30px; color: #6b46c1; filter: drop-shadow(0 2px 4px rgba(255, 255, 255, 0.5)); }
    .interface-text { margin-bottom: 40px; }
    .interface-title { font-size: 28px; font-weight: 600; color: #4c1d95; margin-bottom: 12px; text-shadow: 0 2px 8px rgba(255, 255, 255, 0.5); letter-spacing: -0.025em; }
    .interface-subtitle { font-size: 16px; color: #6b46c1; opacity: 0.8; line-height: 1.5; text-shadow: 0 1px 3px rgba(255, 255, 255, 0.3); }
    .controls { display: flex; gap: 20px; justify-content: center; margin-bottom: 30px; }
    .control-btn { padding: 12px 24px; border: none; border-radius: 25px; font-size: 14px; font-weight: 500; cursor: pointer; transition: all 0.3s ease; backdrop-filter: blur(10px); border: 1px solid rgba(255, 255, 255, 0.2); }
    .voice-btn { background: linear-gradient(135deg, #8b5cf6, #a855f7); color: white; box-shadow: 0 4px 16px rgba(139, 92, 246, 0.3); }
    .voice-btn:hover { transform: translateY(-2px); box-shadow: 0 6px 20px rgba(139, 92, 246, 0.4); }
    .voice-btn.active { background: linear-gradient(135deg, #7c3aed, #8b5cf6); box-shadow: 0 4px 16px rgba(124, 58, 237, 0.5); }
    .voice-btn:disabled { opacity: 0.6; cursor: not-allowed; transform: none; }
    .text-btn { background: rgba(255, 255, 255, 0.2); color: #6b46c1; border: 1px solid rgba(139, 92, 246, 0.3); }
    .text-btn:hover { background: rgba(255, 255, 255, 0.3); transform: translateY(-2px); }
    .text-btn.active { background: rgba(139, 92, 246, 0.2); color: #4c1d95; border: 1px solid rgba(139, 92, 246, 0.5); }
    .chat-container { max-width: 400px; width: 100%; margin: 0 auto; display: none; }
    .chat-container.active { display: block; }
    .chat-messages { height: 300px; overflow-y: auto; padding: 20px; background: rgba(255, 255, 255, 0.1); border-radius: 20px; backdrop-filter: blur(10px); border: 1px solid rgba(255, 255, 255, 0.2); margin-bottom: 20px; }
    .message { margin-bottom: 15px; padding: 12px 16px; border-radius: 18px; max-width: 80%; word-wrap: break-word; }
    .user-message { background: linear-gradient(135deg, #8b5cf6, #a855f7); color: white; margin-left: auto; text-align: right; }
    .ai-message { background: rgba(255, 255, 255, 0.8); color: #4c1d95; margin-right: auto; }
    .chat-input-container { display: flex; gap: 10px; }
    .chat-input { flex: 1; padding: 12px 16px; border: none; border-radius: 25px; background: rgba(255, 255, 255, 0.2); backdrop-filter: blur(10px); border: 1px solid rgba(255, 255, 255, 0.3); color: #4c1d95; font-size: 14px; }
    .chat-input::placeholder { color: #8b5cf6; opacity: 0.7; }
    .send-btn { padding: 12px 16px; border: none; border-radius: 50%; background: linear-gradient(135deg, #8b5cf6, #a855f7); color: white; cursor: pointer; width: 45px; height: 45px; display: flex; align-items: center; justify-content: center; transition: all 0.3s ease; }
    .send-btn:hover { transform: scale(1.1); }
    .status { margin-top: 20px; padding: 8px 16px; border-radius: 15px; font-size: 12px; text-align: center; backdrop-filter: blur(10px); border: 1px solid rgba(255, 255, 255, 0.2); }
    .listening { background: rgba(34, 197, 94, 0.2); color: #15803d; animation: statusPulse 2s ease-in-out infinite; }
    .thinking { background: rgba(251, 191, 36, 0.2); color: #d97706; }
    .inactive { background: rgba(156, 163, 175, 0.2); color: #6b7280; }
    .error { background: rgba(239, 68, 68, 0.2); color: #dc2626; }
    @keyframes statusPulse { 0%, 100% { opacity: 0.7; } 50% { opacity: 1; } }
    @keyframes ringPulse { 0%, 100% { transform: translate(-50%, -50%) scale(1); } 50% { transform: translate(-50%, -50%) scale(1.05); } }
    .close-btn { position: absolute; top: 20px; right: 20px; width: 40px; height: 40px; border: none; border-radius: 50%; background: rgba(255, 255, 255, 0.2); backdrop-filter: blur(10px); border: 1px solid rgba(255, 255, 255, 0.3); color: #6b46c1; cursor: pointer; display: flex; align-items: center; justify-content: center; transition: all 0.3s ease; }
    .close-btn:hover { background: rgba(255, 255, 255, 0.3); transform: scale(1.1); }
    .voice-visualizer { display: none; justify-content: center; align-items: center; gap: 3px; margin-top: 20px; }
    .voice-visualizer.active { display: flex; }
    .voice-bar { width: 4px; height: 20px; background: linear-gradient(to top, #8b5cf6, #c084fc); border-radius: 2px; animation: voiceWave 1s ease-in-out infinite; }
    .voice-bar:nth-child(2) { animation-delay: 0.1s; }
    .voice-bar:nth-child(3) { animation-delay: 0.2s; }
    .voice-bar:nth-child(4) { animation-delay: 0.3s; }
    .voice-bar:nth-child(5) { animation-delay: 0.4s; }
    @keyframes voiceWave { 0%, 100% { height: 20px; } 50% { height: 40px; } }
    @media (max-width: 768px) {
      .interface-container { padding: 40px 20px; }
      .voice-interface { width: 160px; height: 160px; }
      .ring-outer { width: 160px; height: 160px; }
      .ring-middle { width: 110px; height: 110px; }
      .ring-inner { width: 65px; height: 65px; }
      .interface-title { font-size: 24px; }
      .controls { flex-direction: column; align-items: center; }
    }
  </style>
</head>

<body
  data-vapi-public-key="385ecf4c-99a4-4319-8b03-111c6c61abf9"
  data-vapi-assistant-id="900acf00-1429-4a76-92b2-93f0e4ffa109"
>
  <!-- Floating Icon (professional mic icon) -->
  <div class="floating-icon" id="floatingIcon" aria-label="Open AI Assistant" role="button">
    <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" 
         stroke-linecap="round" stroke-linejoin="round" aria-hidden="true">
      <path d="M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3z"/>
      <path d="M19 10v2a7 7 0 0 1-14 0v-2"/>
      <line x1="12" y1="19" x2="12" y2="23"/>
      <line x1="8" y1="23" x2="16" y2="23"/>
    </svg>
  </div>

  <!-- Assistant UI -->
  <div class="holographic-interface" id="holographicInterface">
    <button class="close-btn" id="closeBtn" aria-label="Close assistant">
      <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
        <path d="M6 6L18 18M6 18L18 6"/>
      </svg>
    </button>

    <div class="interface-container">
      <div class="voice-interface">
        <div class="voice-ring ring-outer"></div>
        <div class="voice-ring ring-middle"></div>
        <div class="voice-ring ring-inner">
          <svg class="mic-icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true">
            <path d="M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3z"/>
            <path d="M19 10v2a7 7 0 0 1-14 0v-2"/>
            <line x1="12" y1="19" x2="12" y2="23"/>
            <line x1="8" y1="23" x2="16" y2="23"/>
          </svg>
        </div>
      </div>

      <div class="interface-text">
        <h1 class="interface-title">Advanced voice-activated AI</h1>
        <p class="interface-subtitle">Control your world hands-free with instant voice commands.</p>
      </div>

      <div class="controls">
        <button class="control-btn voice-btn" id="voiceBtn">Voice Chat</button>
        <button class="control-btn text-btn" id="textBtn">Text Chat</button>
      </div>

      <div class="voice-visualizer" id="voiceVisualizer" aria-hidden="true">
        <div class="voice-bar"></div><div class="voice-bar"></div><div class="voice-bar"></div><div class="voice-bar"></div><div class="voice-bar"></div>
      </div>

      <div class="chat-container" id="chatContainer" aria-live="polite">
        <div class="chat-messages" id="chatMessages">
          <div class="message ai-message">Hello! I'm your AI assistant. How can I help you today?</div>
        </div>
        <div class="chat-input-container">
          <input type="text" class="chat-input" id="chatInput" placeholder="Type your message..." />
          <button class="send-btn" id="sendBtn" aria-label="Send message">
            <svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true">
              <path d="M2 3l20 9L2 21v-6l13-2L2 9V3z"/>
            </svg>
          </button>
        </div>
      </div>

      <div class="status inactive" id="status">Ready to assist</div>
    </div>
  </div>

  <script>
  (function () {
    // ---- CONFIGURATION ----
    const PUBLIC_KEY = (document.body.dataset.vapiPublicKey || '').trim();
    const ASSISTANT_ID = (document.body.dataset.vapiAssistantId || '').trim();
    
    // SDK loading approaches - prioritizing working CDN methods
    const SDK_PATHS = [
      // Method 1: Official HTML script tag approach (most reliable for your setup)
      'https://cdn.jsdelivr.net/gh/VapiAI/html-script-tag@latest/dist/assets/index.js',
      
      // Method 2: Try different CDN endpoints for NPM package
      'https://unpkg.com/@vapi-ai/web@latest/dist/index.js',
      'https://unpkg.com/@vapi-ai/web@latest/dist/vapi.js',
      'https://cdn.jsdelivr.net/npm/@vapi-ai/web@latest/dist/index.js',
      'https://cdn.jsdelivr.net/npm/@vapi-ai/web@latest/dist/vapi.js',
      
      // Method 3: Local files (Note: your current vapi.js is CommonJS format and won't work)
      // We'll skip these since your file is Node.js format, not browser format
      // 'assets/vapi.js',  // Your file is CommonJS, not browser-ready
      // 'assets/vapi.browser.js', // Uncomment if you get browser build
    ];

    // ---- STATE ----
    let vapi = null;
    let isListening = false;
    let micStream = null;
    let audioCtx = null;
    let sdkLoaded = false;
    let sdkLoading = false;

    // ---- UI HOOKS ----
    const floatingIcon = document.getElementById('floatingIcon');
    const holo = document.getElementById('holographicInterface');
    const closeBtn = document.getElementById('closeBtn');
    const voiceBtn = document.getElementById('voiceBtn');
    const textBtn = document.getElementById('textBtn');
    const chatContainer = document.getElementById('chatContainer');
    const chatMessages = document.getElementById('chatMessages');
    const chatInput = document.getElementById('chatInput');
    const sendBtn = document.getElementById('sendBtn');
    const statusEl = document.getElementById('status');
    const voiceViz = document.getElementById('voiceVisualizer');

    // ---- UTILITY FUNCTIONS ----
    function setStatus(text, cls) {
      statusEl.textContent = text;
      statusEl.className = `status ${cls}`;
      console.log('[Assistant Status]', text);
    }

    function addMsg(sender, text) {
      const el = document.createElement('div');
      el.className = `message ${sender}-message`;
      el.textContent = text;
      chatMessages.appendChild(el);
      chatMessages.scrollTop = chatMessages.scrollHeight;
    }

    function isSDKReady() {
      return sdkLoaded && (
        (window.Vapi && typeof window.Vapi === 'function') ||
        (window.vapiSDK && typeof window.vapiSDK.run === 'function')
      );
    }

    // ---- DEBUG HELPERS ----
    function debugAudioSetup() {
      console.log('\n🔧 === AUDIO DEBUG INFO ===');
      console.log('AudioContext state:', audioCtx?.state || 'not created');
      console.log('Audio elements on page:', document.querySelectorAll('audio').length);
      
      const audioElements = document.querySelectorAll('audio');
      audioElements.forEach((audio, i) => {
        console.log(`Audio element ${i}:`, {
          id: audio.id,
          src: audio.src,
          autoplay: audio.autoplay,
          muted: audio.muted,
          paused: audio.paused,
          volume: audio.volume,
          readyState: audio.readyState
        });
      });
      
      console.log('Browser info:', {
        userAgent: navigator.userAgent.substring(0, 50) + '...',
        vendor: navigator.vendor,
        platform: navigator.platform
      });
      
      console.log('🔧 === END AUDIO DEBUG ===\n');
    }

    // Add debug button functionality (can be called from console)
    window.debugVapi = debugAudioSetup;
    
    // Add audio test function (can be called from console)
    window.testAudio = async function() {
      console.log('🔊 Testing audio output...');
      try {
        await ensureAudioContext();
        await testAudioOutput();
        
        // Play a test beep
        const audioContext = new (window.AudioContext || window.webkitAudioContext)();
        const oscillator = audioContext.createOscillator();
        const gainNode = audioContext.createGain();
        
        oscillator.connect(gainNode);
        gainNode.connect(audioContext.destination);
        
        oscillator.frequency.value = 440; // A4 note
        gainNode.gain.value = 0.1; // Low volume
        
        oscillator.start();
        setTimeout(() => oscillator.stop(), 500);
        
        console.log('🔊 If you heard a beep, audio output is working!');
        setStatus('🔊 Test beep played - check volume', 'inactive');
      } catch (error) {
        console.error('🔊 Audio test failed:', error);
        setStatus('❌ Audio test failed', 'error');
      }
    };

    // ---- DYNAMIC SDK LOADING ----
    async function loadSDK() {
      if (sdkLoaded || sdkLoading) return sdkLoaded;
      
      sdkLoading = true;
      setStatus('🔄 Loading Vapi SDK...', 'thinking');

      // First check if SDK is already loaded (multiple possible global names)
      if (window.Vapi && typeof window.Vapi === 'function') {
        sdkLoaded = true;
        sdkLoading = false;
        setStatus('✅ SDK ready (Vapi)', 'inactive');
        return true;
      }
      
      if (window.vapiSDK && typeof window.vapiSDK.run === 'function') {
        // HTML script tag approach - normalize to window.Vapi
        window.Vapi = function(publicKey) {
          // Create a wrapper that matches the NPM SDK interface
          let vapiInstance = null;
          
          return {
            start: async function(assistantId) {
              return new Promise((resolve, reject) => {
                try {
                  vapiInstance = window.vapiSDK.run({
                    apiKey: publicKey,
                    assistant: assistantId,
                    config: {}
                  });
                  
                  // The HTML script tag version auto-handles events differently
                  setTimeout(() => resolve({}), 100);
                } catch (error) {
                  reject(error);
                }
              });
            },
            stop: function() {
              // HTML script tag handles this internally
              if (vapiInstance && vapiInstance.stop) {
                vapiInstance.stop();
              }
            },
            send: function(message) {
              // HTML script tag doesn't support send method
              console.warn('[Vapi] Send not supported with HTML script tag approach');
            },
            on: function(event, callback) {
              // HTML script tag handles events differently - we'll emit generic events
              if (event === 'call-start') {
                setTimeout(() => callback(), 200);
              } else if (event === 'call-end') {
                // This will be called when the widget closes
              }
              return this;
            }
          };
        };
        
        sdkLoaded = true;
        sdkLoading = false;
        setStatus('✅ SDK ready (vapiSDK wrapper)', 'inactive');
        return true;
      }

      // Try loading from multiple possible paths
      for (const path of SDK_PATHS) {
        try {
          console.log(`[SDK] Attempting to load from: ${path}`);
          setStatus(`🔄 Trying: ${path.split('/').pop()}...`, 'thinking');
          
          await new Promise((resolve, reject) => {
            const script = document.createElement('script');
            script.src = path;
            script.onload = () => {
              console.log(`[SDK] Successfully loaded script from: ${path}`);
              resolve();
            };
            script.onerror = (error) => {
              console.warn(`[SDK] Failed to load from: ${path}`, error);
              reject(new Error(`Failed to load from ${path}`));
            };
            
            // Add timeout
            setTimeout(() => {
              if (!script.onload.called) {
                reject(new Error(`Timeout loading from ${path}`));
              }
            }, 10000); // Increased timeout to 10 seconds
            
            document.head.appendChild(script);
          });

          // Give a moment for globals to be set
          await new Promise(resolve => setTimeout(resolve, 100));

          // Verify SDK is actually available - check multiple possible global names
          if (window.Vapi && typeof window.Vapi === 'function') {
            console.log('[SDK] Found window.Vapi constructor');
            sdkLoaded = true;
            sdkLoading = false;
            setStatus('✅ SDK loaded successfully (Vapi)', 'inactive');
            return true;
          }
          
          // HTML script tag approach
          if (window.vapiSDK && typeof window.vapiSDK.run === 'function') {
            console.log('[SDK] Found window.vapiSDK.run function - creating enhanced wrapper');
            // Create wrapper to normalize interface
            window.Vapi = function(publicKey) {
              let vapiInstance = null;
              const eventHandlers = {};
              
              return {
                start: async function(assistantId) {
                  return new Promise((resolve, reject) => {
                    try {
                      console.log('[SDK] Starting vapiSDK with enhanced config:', { 
                        publicKey: publicKey.substring(0, 10) + '...', 
                        assistantId 
                      });
                      
                      // Enhanced configuration for better audio handling
                      vapiInstance = window.vapiSDK.run({
                        apiKey: publicKey,
                        assistant: assistantId,
                        config: {
                          position: "bottom-right",
                          offset: "40px",
                          width: "50px",
                          height: "50px",
                          // Audio-specific configurations
                          autoplay: true,
                          muted: false
                        }
                      });
                      
                      console.log('[SDK] vapiSDK instance created:', vapiInstance);
                      
                      // Wait a bit longer for the call to establish and for first message
                      setTimeout(() => {
                        console.log('[SDK] Emitting call-start event');
                        if (eventHandlers['call-start']) {
                          eventHandlers['call-start']();
                        }
                        
                        // Check for any audio elements that might have been created
                        const audioElements = document.querySelectorAll('audio');
                        console.log('[SDK] Audio elements found:', audioElements.length);
                        audioElements.forEach((audio, index) => {
                          console.log(`[SDK] Audio element ${index}:`, {
                            src: audio.src,
                            autoplay: audio.autoplay,
                            muted: audio.muted,
                            paused: audio.paused
                          });
                          
                          // Ensure audio elements are configured for playback
                          audio.autoplay = true;
                          audio.muted = false;
                          if (audio.paused) {
                            audio.play().catch(e => console.warn('[SDK] Audio play failed:', e));
                          }
                        });
                        
                        resolve({});
                      }, 1000);
                    } catch (error) {
                      console.error('[SDK] Error starting vapiSDK:', error);
                      reject(error);
                    }
                  });
                },
                stop: function() {
                  console.log('[SDK] Stopping vapiSDK');
                  if (vapiInstance && vapiInstance.stop) {
                    vapiInstance.stop();
                  }
                  if (eventHandlers['call-end']) {
                    eventHandlers['call-end']();
                  }
                },
                send: function(message) {
                  console.log('[SDK] Send called with:', message);
                  // The HTML script tag approach handles this differently
                  // For now, just log that it's not fully supported
                  console.warn('[Vapi] Send method not fully supported with HTML script tag approach');
                },
                on: function(event, callback) {
                  console.log('[SDK] Event listener registered for:', event);
                  eventHandlers[event] = callback;
                  return this;
                }
              };
            };
            
            sdkLoaded = true;
            sdkLoading = false;
            setStatus('✅ SDK loaded successfully (vapiSDK)', 'inactive');
            return true;
          }

          console.warn(`[SDK] Script loaded from ${path} but no recognized globals found`);
          console.log('[SDK] Available globals:', Object.keys(window).filter(key => key.toLowerCase().includes('vapi')));
          
        } catch (error) {
          console.warn(`[SDK] Error loading from ${path}:`, error.message);
          // Continue to next path
          continue;
        }
      }

      // If we get here, all paths failed
      sdkLoading = false;
      const errorMsg = '❌ Cannot load Vapi SDK from CDN. Check internet connection.';
      setStatus(errorMsg, 'error');
      console.error('[SDK] Load failed. Tried paths:', SDK_PATHS);
      console.error('[SDK] Common causes:');
      console.error('  1. No internet connection or CDN blocked');
      console.error('  2. Your local vapi.js file is Node.js format (has "exports", "require") - not browser compatible');
      console.error('  3. Need to use CDN or get browser build of Vapi SDK');
      console.log('[SDK] Your local file at docs/assets/vapi.js is CommonJS format and cannot be used in browsers');
      console.log('[SDK] The app will try CDN loading which should work if you have internet access');
      return false;
    }

    // ---- AUDIO + MIC HELPERS ----
    async function ensureAudioContext() {
      try {
        if (!audioCtx) {
          const AC = window.AudioContext || window.webkitAudioContext;
          if (AC) {
            audioCtx = new AC();
            console.log('[Audio] AudioContext created');
          } else {
            throw new Error('AudioContext not supported');
          }
        }
        if (audioCtx.state === 'suspended') {
          await audioCtx.resume();
          console.log('[Audio] AudioContext resumed from suspended state');
        }
        console.log('[Audio] AudioContext state:', audioCtx.state);
        return true;
      } catch (e) {
        console.warn('AudioContext setup failed:', e);
        return false;
      }
    }

    // Add audio element to handle AI voice output
    function ensureAudioOutput() {
      // Create a dedicated audio element for AI voice if it doesn't exist
      let aiAudioElement = document.getElementById('vapi-ai-audio');
      if (!aiAudioElement) {
        aiAudioElement = document.createElement('audio');
        aiAudioElement.id = 'vapi-ai-audio';
        aiAudioElement.autoplay = true;
        aiAudioElement.style.display = 'none';
        document.body.appendChild(aiAudioElement);
        console.log('[Audio] Created AI audio output element');
      }
      return aiAudioElement;
    }

    // Test audio output capability
    async function testAudioOutput() {
      try {
        const aiAudio = ensureAudioOutput();
        // Test if we can play a silent audio to unlock autoplay
        const audioData = 'data:audio/wav;base64,UklGRigAAABXQVZFZm10IBIAAAABAAEARKwAAIhYAQACABAAAABkYXRhAgAAAAEA';
        aiAudio.src = audioData;
        await aiAudio.play();
        console.log('[Audio] Test audio playback successful');
        return true;
      } catch (e) {
        console.warn('[Audio] Test audio playback failed:', e);
        return false;
      }
    }

    async function ensureMic() {
      if (micStream && micStream.active) return true;
      
      try {
        micStream = await navigator.mediaDevices.getUserMedia({ 
          audio: { 
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true
          } 
        });
        console.log('[Mic] Permission granted and stream active');
        return true;
      } catch (err) {
        console.error('Microphone access failed:', err);
        
        let errorMsg = '❌ Microphone access denied';
        if (err.name === 'NotFoundError') {
          errorMsg = '❌ No microphone found';
        } else if (err.name === 'NotAllowedError') {
          errorMsg = '❌ Microphone permission denied';
        } else if (err.name === 'NotReadableError') {
          errorMsg = '❌ Microphone is busy or unavailable';
        }
        
        setStatus(errorMsg, 'error');
        return false;
      }
    }

    function releaseMic(reason = '') {
      if (micStream) {
        try {
          micStream.getTracks().forEach(track => {
            track.stop();
            console.log('[Mic] Track stopped:', track.kind);
          });
        } catch (e) {
          console.warn('[Mic] Error stopping tracks:', e);
        }
        micStream = null;
        if (reason) console.log('[Mic] Released:', reason);
      }
    }

    // ---- VOICE FUNCTIONALITY ----
    async function startVoice() {
      // Disable button to prevent double-clicks
      voiceBtn.disabled = true;
      
      try {
        // 1. Ensure SDK is loaded
        if (!(await loadSDK())) {
          return;
        }

        // 2. Validate configuration
        if (!PUBLIC_KEY || !ASSISTANT_ID) {
          setStatus('❌ Missing Vapi configuration keys', 'error');
          console.error('Missing keys. Check data-vapi-public-key and data-vapi-assistant-id on <body>.');
          return;
        }

        // 3. Setup audio context (required for autoplay policies)
        console.log('[Audio] Setting up audio context and output...');
        await ensureAudioContext();
        
        // 4. Test and prepare audio output
        ensureAudioOutput();
        await testAudioOutput();

        // 5. Request microphone permission
        if (!(await ensureMic())) {
          return;
        }

        // 6. Initialize Vapi client if needed
        if (!vapi) {
          // Normalize SDK reference (some CDNs use different global names)
          const VapiClass = window.Vapi || window.VapiSDK;
          if (!VapiClass) {
            throw new Error('Vapi SDK not found after loading');
          }
          
          console.log('[Vapi] Creating new Vapi instance...');
          vapi = new VapiClass(PUBLIC_KEY);

          // Setup comprehensive event handling
          vapi.on('call-start', (params) => {
            console.log('[Vapi] ✅ Call started - AI should speak soon:', params);
            isListening = true;
            setStatus('🔴 Connected - AI will speak first', 'listening');
            voiceViz.classList.add('active');
            
            // Additional audio setup after call starts
            setTimeout(() => {
              ensureAudioOutput();
              console.log('[Audio] Audio output re-ensured after call start');
              
              // If user still doesn't hear anything after 3 seconds, show help
              setTimeout(() => {
                if (isListening) {
                  console.log('💡 If you don\'t hear the AI speaking:');
                  console.log('  1. Check your volume/mute settings');
                  console.log('  2. Type: testAudio() in console to test speakers');
                  console.log('  3. Type: debugVapi() in console for detailed info');
                  setStatus('🔴 Connected - No audio? Check volume/speakers', 'listening');
                  
                  // Show detailed help after 6 seconds
                  setTimeout(() => {
                    if (isListening) {
                      setStatus('💡 Open browser console (F12) for audio help', 'thinking');
                    }
                  }, 3000);
                }
              }, 3000);
            }, 100);
          });

          vapi.on('call-end', (params) => {
            console.log('[Vapi] Call ended:', params);
            isListening = false;
            setStatus('✅ Ready to assist', 'inactive');
            voiceViz.classList.remove('active');
            voiceBtn.disabled = false;
            releaseMic('call ended');
          });

          vapi.on('speech-start', () => {
            console.log('[Vapi] 🎤 User speech started');
            voiceViz.classList.add('active');
            setStatus('🎤 Listening...', 'listening');
          });

          vapi.on('speech-end', () => {
            console.log('[Vapi] 🎤 User speech ended');
            voiceViz.classList.remove('active');
            setStatus('🤖 AI responding...', 'thinking');
          });

          vapi.on('message', (message) => {
            console.log('[Vapi] Message received:', message);
            
            if (message?.type === 'transcript' && message.transcriptType === 'final') {
              addMsg('user', message.transcript);
            }
            
            if (message?.type === 'assistant-response' && message.message) {
              addMsg('ai', message.message);
              setStatus('🔴 Connected - Speak now!', 'listening');
            }

            // Log any function calls or other message types
            if (message?.type === 'function-call') {
              console.log('[Vapi] Function call:', message);
            }
          });

          vapi.on('error', (error) => {
            console.error('[Vapi] ❌ Error:', error);
            isListening = false;
            voiceViz.classList.remove('active');
            voiceBtn.disabled = false;
            
            let errorMsg = '❌ Voice error occurred';
            if (error.message) {
              errorMsg += `: ${error.message}`;
            }
            setStatus(errorMsg, 'error');
            
            setTimeout(() => releaseMic('error occurred'), 1000);
          });

          // Additional event listeners for debugging audio
          if (typeof vapi.on === 'function') {
            vapi.on('webrtc-state', (state) => console.log('[Vapi] WebRTC state:', state));
            vapi.on('status', (status) => console.log('[Vapi] Status:', status));
            vapi.on('volume-level', (volume) => console.log('[Vapi] AI volume level:', volume));
          }
        }

        // 7. Start the voice call
        setStatus('🎤 Starting voice connection...', 'thinking');
        console.log('[Vapi] Starting call with assistant:', ASSISTANT_ID);
        console.log('[Vapi] Expected: AI should speak first with greeting message');
        
        const result = await vapi.start(ASSISTANT_ID);
        console.log('[Vapi] Start result:', result);

        // Extra debugging for audio
        setTimeout(() => {
          console.log('[Debug] Call state after 2 seconds:');
          console.log('  - isListening:', isListening);
          console.log('  - Audio elements:', document.querySelectorAll('audio').length);
          console.log('  - AudioContext state:', audioCtx?.state);
          
          if (isListening) {
            console.log('[Debug] ✅ Call is active - if you don\'t hear AI, check:');
            console.log('  1. Volume/mute settings');
            console.log('  2. Assistant configuration (first message)');
            console.log('  3. Browser autoplay policy');
          }
        }, 2000);

      } catch (error) {
        console.error('[Voice] Start failed:', error);
        isListening = false;
        voiceBtn.disabled = false;
        voiceViz.classList.remove('active');
        
        let errorMsg = '❌ Failed to start voice chat';
        if (error.message) {
          errorMsg += `: ${error.message}`;
        }
        setStatus(errorMsg, 'error');
        
        releaseMic('start failed');
      } finally {
        // Re-enable button after a delay to prevent rapid clicking
        setTimeout(() => {
          if (!isListening) {
            voiceBtn.disabled = false;
          }
        }, 2000);
      }
    }

    function stopVoice() {
      try {
        if (vapi && typeof vapi.stop === 'function') {
          vapi.stop();
          console.log('[Vapi] Stop called');
        }
      } catch (e) {
        console.warn('[Vapi] Stop error:', e);
      }
      
      isListening = false;
      voiceBtn.disabled = false;
      voiceViz.classList.remove('active');
      setStatus('Text mode active', 'inactive');
      releaseMic('manual stop');
    }

    // ---- TEXT CHAT FUNCTIONALITY ----
    function sendTextMessage() {
      const msg = chatInput.value.trim();
      if (!msg) return;
      
      addMsg('user', msg);
      chatInput.value = '';
      
      if (isListening && vapi && typeof vapi.send === 'function') {
        try {
          vapi.send({ 
            type: 'add-message', 
            message: { role: 'user', content: msg } 
          });
          setStatus('AI thinking…', 'thinking');
        } catch (e) {
          console.warn('[Text] Failed to send via Vapi:', e);
          // Fallback to mock response
          setTimeout(() => {
            addMsg('ai', "I'm here and listening. What would you like to do next?");
            setStatus('Text mode active', 'inactive');
          }, 700);
        }
      } else {
        // Mock AI response for text mode
        setStatus('AI thinking…', 'thinking');
        setTimeout(() => {
          addMsg('ai', "I'm here and listening. What would you like to do next?");
          setStatus('Text mode active', 'inactive');
        }, 700);
      }
    }

    // ---- EVENT LISTENERS ----
    floatingIcon.addEventListener('click', () => {
      holo.classList.add('active');
      setStatus('Choose Voice or Text mode', 'inactive');
    });

    closeBtn.addEventListener('click', () => {
      holo.classList.remove('active');
      stopVoice();
    });

    voiceBtn.addEventListener('click', () => {
      voiceBtn.classList.add('active');
      textBtn.classList.remove('active');
      chatContainer.classList.remove('active');
      startVoice();
    });

    textBtn.addEventListener('click', () => {
      textBtn.classList.add('active');
      voiceBtn.classList.remove('active');
      chatContainer.classList.add('active');
      stopVoice();
      
      // Focus input after a brief delay to ensure it's visible
      setTimeout(() => chatInput.focus(), 100);
    });

    sendBtn.addEventListener('click', sendTextMessage);

    chatInput.addEventListener('keypress', (e) => {
      if (e.key === 'Enter') {
        e.preventDefault();
        sendTextMessage();
      }
    });

    // ---- CLEANUP ----
    window.addEventListener('beforeunload', () => {
      stopVoice();
      releaseMic('page unload');
    });

    // ---- INITIALIZATION ----
    console.log('[Assistant] Initialized - GitHub Pages build with CDN SDK loading');
    console.log('[Assistant] Note: Your local docs/assets/vapi.js is CommonJS format and cannot be used in browsers');
    console.log('[Assistant] Will load browser-compatible SDK from CDN:', SDK_PATHS.slice(0, 2));
    console.log('[Assistant] If you see "Cannot load Vapi SDK" - check your internet connection');
    
    // Immediate SDK loading attempt for better user feedback
    loadSDK().then(success => {
      if (success) {
        console.log('[Assistant] ✅ SDK loaded successfully on page load');
      } else {
        console.warn('[Assistant] ❌ Failed to load SDK on page load - will retry when user clicks voice');
      }
    }).catch(e => {
      console.warn('[SDK] Initial load failed:', e.message);
    });
    
    // Backup: Try to preload SDK on DOM ready
    document.addEventListener('DOMContentLoaded', () => {
      if (!sdkLoaded) {
        console.log('[Assistant] Retrying SDK load on DOM ready...');
        loadSDK().catch(e => console.warn('[SDK] DOM ready load failed:', e));
      }
    });

  })();
</script>
</body>
</html>
